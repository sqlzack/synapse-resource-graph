{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Set Variables and Import Modules for use throughout Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "resourceGraphURL = 'https://management.azure.com/providers/Microsoft.ResourceGraph/resources?api-version=2020-04-01-preview'\n",
        "\n",
        "resourceGraphQuery = \"\"\"\n",
        "securityresources\n",
        "| where type == 'microsoft.security/assessments'\n",
        "| where properties.metadata.severity == 'High'\n",
        "| where properties.metadata.implementationEffort == 'Low'\n",
        "| summarize ThreatCount=count() by Threats=tostring(properties.metadata.threats) \t\n",
        "\"\"\"\n",
        "\n",
        "saveDestination = \"<put abfss location here>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create the POST call to the REST API "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def callAPI(skipToken = \"\"):\n",
        "    token = mssparkutils.credentials.getToken('AzureManagement')\n",
        "    auth_headers = {'Authorization': 'Bearer ' + token}\n",
        "\n",
        "    if skipToken != \"\":\n",
        "        data = {\"query\": resourceGraphQuery,\"options\":{\"$skipToken\": skipToken} }\n",
        "    else:\n",
        "        data = {\"query\": resourceGraphQuery}\n",
        "\n",
        "    resourceGraphResponse = requests.post(resourceGraphURL,headers=auth_headers,json=data)\n",
        "\n",
        "    responseJSON = resourceGraphResponse.text\n",
        "\n",
        "    return responseJSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create a Python Function to parse API Response into a usable Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def parseResponse(responseJSONText):\n",
        "    # Parallelize JSON string using Spark Context into a Pyspark Data Frame\n",
        "    responseDF=spark.read.json(sc.parallelize([responseJSON]))\n",
        "\n",
        "    # Create a temp view so data can be transformed using SQL\n",
        "    responseDF.createOrReplaceTempView(\"v_tempJSON\")\n",
        "\n",
        "    # SQL Query used to parse the responseDF\n",
        "    sqlQuery = \"\"\"\n",
        "    WITH baseExplode AS\n",
        "    (\n",
        "    SELECT explode(data.rows) rowData\n",
        "    FROM v_tempJSON\n",
        "    )\n",
        "    SELECT  rowData[0] ThreatName\n",
        "            ,rowData[1] ThreatCount\n",
        "    FROM baseExplode\n",
        "    \"\"\"\n",
        "\n",
        "    # Parse response using Spark SQL\n",
        "    dfParsedResponse = spark.sql(sqlQuery)\n",
        "\n",
        "    return dfParsedResponse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Run initial process to extract data from REST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save Response Text from API to a variable\n",
        "responseText = callAPI()\n",
        "\n",
        "# Parse Columns in Response Text to a Data Frame\n",
        "dfParsedResponse = parseResponse(responseText)\n",
        "\n",
        "# Write the Data Frame to Parquet files on storage.\n",
        "dfParsedResponse.write.mode(\"overwrite\").parquet(saveDestination)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Check if API returned a Skip Token and run until it does not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Format Response Text to JSON\n",
        "responseJSON = json.loads(responseText)\n",
        "\n",
        "# Evaluate whether response contains a Skip Token\n",
        "while \"$skipToken\" in responseJSON:\n",
        "    # Set Skip Token Variable\n",
        "    skiptoken = responseJSON[\"$skipToken\"]\n",
        "\n",
        "    # Call the API using the Skip Token option\n",
        "    responseText = callAPI(skiptoken)\n",
        "\n",
        "    # Set a new response variable to be evaluated in while loop\n",
        "    responseJSON = json.loads(responseText)\n",
        "\n",
        "    # Create a new data frame from new API Response\n",
        "    dfParsedResponse = parseResponse(responseText)\n",
        "\n",
        "    # Append Parquet table created in previous steps.\n",
        "    dfParsedResponse.write.mode(\"append\").parquet(saveDestination)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### __OPTIONAL__: Create Table in Lake Database to make for easy Power BI integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {},
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create query variable (I like to format as multi-line, hence the triple quotes)\n",
        "createTableStatement = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS resourceGraphLakeDb.threatSummary\n",
        "USING PARQUET\n",
        "LOCATION '{saveDestination}'\n",
        "\"\"\"\n",
        "\n",
        "# Create database and table if they do not exist.\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS resourceGraphLakeDb\")\n",
        "spark.sql(createTableStatement)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
